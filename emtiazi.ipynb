{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hazm import *\n",
    "\n",
    "jhanr_dic = {\n",
    "    'کلمات' : 0,\n",
    "    'جامعه\\u200cشناسی' : 1 ,\n",
    "    'کلیات اسلام' : 2 ,\n",
    "    'داستان کودک و نوجوانان' : 3, \n",
    "    'داستان کوتاه' : 4,\n",
    "    'مدیریت و کسب و کار' : 5,\n",
    "    'رمان' : 6\n",
    "}\n",
    "\n",
    "translator_jhanr = {\n",
    "    0 : 'جامعه\\u200cشناسی',\n",
    "    1 : 'کلیات اسلام' ,\n",
    "    2 : 'داستان کودک و نوجوانان', \n",
    "    3 : 'داستان کوتاه',\n",
    "    4 : 'مدیریت و کسب و کار',\n",
    "    5 : 'رمان'\n",
    "}\n",
    "\n",
    "words_dict = {}\n",
    "\n",
    "def add_new_word(matris, word):\n",
    "    matris[jhanr_dic['کلمات']].append(word)\n",
    "    for i in range(1, 7):\n",
    "        matris[i].append(0)\n",
    "    return matris\n",
    "\n",
    "def delete_sw(info):\n",
    "    sw_pd = open(\"sw.csv\", 'r')\n",
    "    stop_words = sw_pd.read()\n",
    "    stop_words = stop_words.split(\"\\n\")\n",
    "    for i in range(0, len(stop_words)):\n",
    "        while stop_words[i] in info:\n",
    "            info.remove(stop_words[i])\n",
    "    return info\n",
    "\n",
    "# def stemmering(info):\n",
    "#     stemmer = Stemmer()\n",
    "#     for i in range(len(info)):\n",
    "#             if not info[i].isnumeric():\n",
    "#                 info[i] = stemmer.stem(info[i])\n",
    "#     return info\n",
    "\n",
    "def lemmetizing(info):\n",
    "    lemmetizer = Lemmatizer()\n",
    "    for i in range(len(info)):\n",
    "            if not info[i].isnumeric():\n",
    "                info[i] = lemmetizer.lemmatize(info[i])\n",
    "    return info\n",
    "\n",
    "def clean_txt(info):\n",
    "    punctuaitions = ['(', '-', ')', '»', '«', '.', ':', '...', '،', '!', '؟', '/', '\\\\']\n",
    "    for i in range(0, len(punctuaitions)):\n",
    "        while punctuaitions[i] in info:\n",
    "            info.remove(punctuaitions[i])\n",
    "    info = delete_sw(info)\n",
    "    info = lemmetizing(info)\n",
    "    # info = stemmering(info)\n",
    "    return info\n",
    "\n",
    "books_train = pd.read_csv(\"books_train.csv\")\n",
    "books_test = pd.read_csv(\"books_test.csv\")\n",
    "normalizer = Normalizer()\n",
    "splited_train_description = books_train['description'].apply(word_tokenize)\n",
    "splited_train_description = splited_train_description.apply(clean_txt)\n",
    "splited_test_description = word_tokenize(str(splited_train_description))\n",
    "splited_test_description = books_test['description'].apply(word_tokenize)\n",
    "splited_test_description = splited_test_description.apply(clean_txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bow = []\n",
    "for i in range(0, 7):\n",
    "    row = []\n",
    "    train_bow.append(row)\n",
    "for i in range(len(splited_train_description)):\n",
    "    for j in range(len(splited_train_description[i])):\n",
    "        if splited_train_description[i][j] in train_bow[jhanr_dic['کلمات']]:\n",
    "            train_bow[jhanr_dic[books_train['categories'][i]]][words_dict[splited_train_description[i][j]][0]] += 1\n",
    "        elif not splited_train_description[i][j].isnumeric():\n",
    "            train_bow = add_new_word(train_bow, splited_train_description[i][j])\n",
    "            words_dict[splited_train_description[i][j]] = []\n",
    "            words_dict[splited_train_description[i][j]].append(len(words_dict) - 1)\n",
    "            train_bow[jhanr_dic[books_train['categories'][i]]][words_dict[splited_train_description[i][j]][0]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy with out additive smooth is:\n",
      "0.29555555555555557\n"
     ]
    }
   ],
   "source": [
    "def find_max_index(probabilities):\n",
    "    max_index = 0\n",
    "    for i in range(1, len(probabilities)):\n",
    "        if probabilities[i] > probabilities[max_index]:\n",
    "            max_index = i\n",
    "    return max_index\n",
    "\n",
    "def predict_jhanr_wt_ads(train_bow, description):\n",
    "    probabilities = []\n",
    "    for i in range(jhanr_dic['جامعه\\u200cشناسی'], len(jhanr_dic)):\n",
    "        makhrej = 0\n",
    "        probability = 1\n",
    "        for j in range(len(train_bow[i])):\n",
    "            if str(train_bow[i][j]).isnumeric():\n",
    "                makhrej += train_bow[i][j]\n",
    "        for k in range(len(description)):\n",
    "            if (description[k] in train_bow[jhanr_dic['کلمات']] and \n",
    "                str(train_bow[i][words_dict[description[k]][0]]).isnumeric()):\n",
    "                probability *= (train_bow[i][words_dict[description[k]][0]] / makhrej)\n",
    "        probabilities.append(probability)\n",
    "    return translator_jhanr[find_max_index(probabilities)]\n",
    "\n",
    "def accuracy_percentage(testing_data, given_data):\n",
    "    num_of_currect = 0\n",
    "    for i in range(len(testing_data)):\n",
    "        if testing_data[i] == given_data[i]:\n",
    "            num_of_currect += 1\n",
    "    return num_of_currect / len(given_data)\n",
    "\n",
    "prediction_result_without_ads = []\n",
    "for i in range(len(splited_test_description)):\n",
    "    prediction_result_without_ads.append(predict_jhanr_wt_ads(train_bow, splited_test_description[i]))\n",
    "print(\"accuracy with out additive smooth is:\")\n",
    "print(accuracy_percentage(prediction_result_without_ads, books_test['categories']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy with additive smooth and log is:\n",
      "0.8111111111111111\n"
     ]
    }
   ],
   "source": [
    "def find_max_index(probabilities):\n",
    "    max_index = 0\n",
    "    for i in range(1, len(probabilities)):\n",
    "        if probabilities[i] > probabilities[max_index]:\n",
    "            max_index = i\n",
    "    return max_index\n",
    "\n",
    "def predict_jhanr_wt_ads(train_bow, description):\n",
    "    probabilities = []\n",
    "    a = 0.35\n",
    "    for i in range(jhanr_dic['جامعه\\u200cشناسی'], len(jhanr_dic)):\n",
    "        N_Wi = 0\n",
    "        probability = 0\n",
    "        d = 0\n",
    "        for j in range(len(train_bow[i])):\n",
    "            if str(train_bow[i][j]).isnumeric():\n",
    "                N_Wi += train_bow[i][j]\n",
    "            if str(train_bow[i][j]).isnumeric() and train_bow[i][j] != 0:\n",
    "                d += 1\n",
    "        for k in range(len(description)):\n",
    "            if (description[k] in train_bow[jhanr_dic['کلمات']] and \n",
    "                str(train_bow[i][words_dict[description[k]][0]]).isnumeric()):\n",
    "                probability += np.log10((train_bow[i][words_dict[description[k]][0]] + a) / (N_Wi + a * d))\n",
    "            elif not description[k].isnumeric():\n",
    "                probability += np.log10((a) / (N_Wi + a * d))\n",
    "        probabilities.append(probability)\n",
    "    return translator_jhanr[find_max_index(probabilities)]\n",
    "\n",
    "def accuracy_percentage(testing_data, given_data):\n",
    "    num_of_currect = 0\n",
    "    for i in range(len(testing_data)):\n",
    "        if testing_data[i] == given_data[i]:\n",
    "            num_of_currect += 1\n",
    "    return num_of_currect / len(given_data)\n",
    "\n",
    "prediction_result_without_ads = []\n",
    "for i in range(len(splited_test_description)):\n",
    "    prediction_result_without_ads.append(predict_jhanr_wt_ads(train_bow, splited_test_description[i]))\n",
    "print(\"accuracy with additive smooth and log is:\")\n",
    "print(accuracy_percentage(prediction_result_without_ads, books_test['categories']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
